{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/33/9m74m8_s3z39fzxgyl19cfjh0000gn/T/ipykernel_3613/3385316513.py:1: DtypeWarning: Columns (0) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('/Users/iarv/Documents/Codes/backorder-prediction-old/data/raw/Kaggle_Training_Dataset_v2.csv')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1687861, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>national_inv</th>\n",
       "      <th>lead_time</th>\n",
       "      <th>in_transit_qty</th>\n",
       "      <th>forecast_3_month</th>\n",
       "      <th>forecast_6_month</th>\n",
       "      <th>forecast_9_month</th>\n",
       "      <th>sales_1_month</th>\n",
       "      <th>sales_3_month</th>\n",
       "      <th>sales_6_month</th>\n",
       "      <th>...</th>\n",
       "      <th>pieces_past_due</th>\n",
       "      <th>perf_6_month_avg</th>\n",
       "      <th>perf_12_month_avg</th>\n",
       "      <th>local_bo_qty</th>\n",
       "      <th>deck_risk</th>\n",
       "      <th>oe_constraint</th>\n",
       "      <th>ppap_risk</th>\n",
       "      <th>stop_auto_buy</th>\n",
       "      <th>rev_stop</th>\n",
       "      <th>went_on_backorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1026827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1043384</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1043696</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1043852</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1044048</td>\n",
       "      <td>8.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>-99.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       sku  national_inv  lead_time  in_transit_qty  forecast_3_month   \n",
       "0  1026827           0.0        NaN             0.0               0.0  \\\n",
       "1  1043384           2.0        9.0             0.0               0.0   \n",
       "2  1043696           2.0        NaN             0.0               0.0   \n",
       "3  1043852           7.0        8.0             0.0               0.0   \n",
       "4  1044048           8.0        NaN             0.0               0.0   \n",
       "\n",
       "   forecast_6_month  forecast_9_month  sales_1_month  sales_3_month   \n",
       "0               0.0               0.0            0.0            0.0  \\\n",
       "1               0.0               0.0            0.0            0.0   \n",
       "2               0.0               0.0            0.0            0.0   \n",
       "3               0.0               0.0            0.0            0.0   \n",
       "4               0.0               0.0            0.0            0.0   \n",
       "\n",
       "   sales_6_month  ...  pieces_past_due  perf_6_month_avg perf_12_month_avg   \n",
       "0            0.0  ...              0.0            -99.00            -99.00  \\\n",
       "1            0.0  ...              0.0              0.99              0.99   \n",
       "2            0.0  ...              0.0            -99.00            -99.00   \n",
       "3            0.0  ...              0.0              0.10              0.13   \n",
       "4            0.0  ...              0.0            -99.00            -99.00   \n",
       "\n",
       "   local_bo_qty  deck_risk  oe_constraint  ppap_risk stop_auto_buy rev_stop   \n",
       "0           0.0         No             No         No           Yes       No  \\\n",
       "1           0.0         No             No         No           Yes       No   \n",
       "2           0.0        Yes             No         No           Yes       No   \n",
       "3           0.0         No             No         No           Yes       No   \n",
       "4           0.0        Yes             No         No           Yes       No   \n",
       "\n",
       "  went_on_backorder  \n",
       "0                No  \n",
       "1                No  \n",
       "2                No  \n",
       "3                No  \n",
       "4                No  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/iarv/Documents/Codes/backorder-prediction-old/data/raw/Kaggle_Training_Dataset_v2.csv')\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1687861 entries, 0 to 1687860\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count    Dtype  \n",
      "---  ------             --------------    -----  \n",
      " 0   sku                1687861 non-null  object \n",
      " 1   national_inv       1687860 non-null  float64\n",
      " 2   lead_time          1586967 non-null  float64\n",
      " 3   in_transit_qty     1687860 non-null  float64\n",
      " 4   forecast_3_month   1687860 non-null  float64\n",
      " 5   forecast_6_month   1687860 non-null  float64\n",
      " 6   forecast_9_month   1687860 non-null  float64\n",
      " 7   sales_1_month      1687860 non-null  float64\n",
      " 8   sales_3_month      1687860 non-null  float64\n",
      " 9   sales_6_month      1687860 non-null  float64\n",
      " 10  sales_9_month      1687860 non-null  float64\n",
      " 11  min_bank           1687860 non-null  float64\n",
      " 12  potential_issue    1687860 non-null  object \n",
      " 13  pieces_past_due    1687860 non-null  float64\n",
      " 14  perf_6_month_avg   1687860 non-null  float64\n",
      " 15  perf_12_month_avg  1687860 non-null  float64\n",
      " 16  local_bo_qty       1687860 non-null  float64\n",
      " 17  deck_risk          1687860 non-null  object \n",
      " 18  oe_constraint      1687860 non-null  object \n",
      " 19  ppap_risk          1687860 non-null  object \n",
      " 20  stop_auto_buy      1687860 non-null  object \n",
      " 21  rev_stop           1687860 non-null  object \n",
      " 22  went_on_backorder  1687860 non-null  object \n",
      "dtypes: float64(15), object(8)\n",
      "memory usage: 296.2+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sku column is irrelevent so it need to be dropped\n",
    "df.drop(columns=['sku'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "national_inv              1\n",
       "lead_time            100894\n",
       "in_transit_qty            1\n",
       "forecast_3_month          1\n",
       "forecast_6_month          1\n",
       "forecast_9_month          1\n",
       "sales_1_month             1\n",
       "sales_3_month             1\n",
       "sales_6_month             1\n",
       "sales_9_month             1\n",
       "min_bank                  1\n",
       "potential_issue           1\n",
       "pieces_past_due           1\n",
       "perf_6_month_avg          1\n",
       "perf_12_month_avg         1\n",
       "local_bo_qty              1\n",
       "deck_risk                 1\n",
       "oe_constraint             1\n",
       "ppap_risk                 1\n",
       "stop_auto_buy             1\n",
       "rev_stop                  1\n",
       "went_on_backorder         1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset has 1 abnormal row : last row\n",
    "df = df[:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "national_inv              0\n",
       "lead_time            100893\n",
       "in_transit_qty            0\n",
       "forecast_3_month          0\n",
       "forecast_6_month          0\n",
       "forecast_9_month          0\n",
       "sales_1_month             0\n",
       "sales_3_month             0\n",
       "sales_6_month             0\n",
       "sales_9_month             0\n",
       "min_bank                  0\n",
       "potential_issue           0\n",
       "pieces_past_due           0\n",
       "perf_6_month_avg          0\n",
       "perf_12_month_avg         0\n",
       "local_bo_qty              0\n",
       "deck_risk                 0\n",
       "oe_constraint             0\n",
       "ppap_risk                 0\n",
       "stop_auto_buy             0\n",
       "rev_stop                  0\n",
       "went_on_backorder         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['potential_issue', 'deck_risk', 'oe_constraint', 'ppap_risk',\n",
       "        'stop_auto_buy', 'rev_stop'],\n",
       "       dtype='object'),\n",
       " Index(['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3_month',\n",
       "        'forecast_6_month', 'forecast_9_month', 'sales_1_month',\n",
       "        'sales_3_month', 'sales_6_month', 'sales_9_month', 'min_bank',\n",
       "        'pieces_past_due', 'perf_6_month_avg', 'perf_12_month_avg',\n",
       "        'local_bo_qty'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_name = 'went_on_backorder'\n",
    "X, y = df.drop(target_name, axis=1), df[target_name]\n",
    "\n",
    "obj_cols = X.select_dtypes('object').columns\n",
    "num_cols = X.select_dtypes(['float64', 'int64']).columns\n",
    "\n",
    "obj_cols, num_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 10))\n",
    "# sns.heatmap(df[num_cols].corr(), annot=True, fmt='.2f', square=True, cbar=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Observation\n",
    "\n",
    "- forcast_3_month, forcast_6_month, forcast_9_month are highly correlated.\n",
    "- sales_3_month, sales_6_month, sales_9_month are highly correlated.\n",
    "\n",
    "#### Take only 1 from each of the highly correlated features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "went_on_backorder\n",
       "No     99.330928\n",
       "Yes     0.669072\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['went_on_backorder'].value_counts(True) * 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### This is highly imbalanced dataset because it has only **0.67%** of data as labeled as **YES** and other **99.3%** data labeled as **NO**.\n",
    "\n",
    "> I need to perform data upsampling or downsampling method to work with this dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Requirements for model building for backorder dataset\n",
    "\n",
    "0. Do all this with sklearn `Pipeline` and `ColumnTransformer` and then transform the data with this.\n",
    "1. Impute the numerical values with `SimpleImputer(strategy='median')` and scale the numerical values with `MinMaxScaler()`.\n",
    "2. Encode the categorical values with `OrdinalEncoder()` all the categorical feature has `['Yes', 'No']` category values only.\n",
    "3. Peform **Up-Sampling** or **Down-Sampling** on the `went_on_backorder` target feature to balance the dataset.\n",
    "4. Split the data with `train_test_split` and then transform the data with `ColumnTransformer` object which you previously build.\n",
    "5. Perform `PCA()` on the dataset and select the **best 6-15 feature** of the dataset.\n",
    "6. Build the model with ML Algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, roc_auc_score\n",
    "\n",
    "def backorder_model(df):\n",
    "    # Create the pipeline for numerical features\n",
    "    numerical_transformer = Pipeline([\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "\n",
    "    # Create the pipeline for categorical features\n",
    "    categorical_transformer = Pipeline([\n",
    "        ('encoder', OrdinalEncoder())\n",
    "    ])\n",
    "\n",
    "    # Combine the numerical and categorical pipelines\n",
    "    # preprocessor = ColumnTransformer([\n",
    "    #     ('numerical', numerical_transformer, ['national_inv', 'lead_time', 'in_transit_qty', 'forecast_3m', 'forecast_6m', 'forecast_9m', 'sales_1m', 'sales_3m', 'sales_6m', 'sales_9m']),\n",
    "    #     ('categorical', categorical_transformer, ['product_category', 'subcategory', 'brand'])\n",
    "    # ])\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('numerical', numerical_transformer, num_cols),\n",
    "        ('categorical', categorical_transformer, obj_cols)\n",
    "    ])\n",
    "\n",
    "    # Upsample the minority class\n",
    "    majority = df[df['went_on_backorder'] == 'No']\n",
    "    minority = df[df['went_on_backorder'] == 'Yes']\n",
    "    upsampled_minority = resample(minority, replace=True, n_samples=len(majority), random_state=0)\n",
    "    df = pd.concat([majority, upsampled_minority])\n",
    "\n",
    "    # Tranform the data with preprocessor pipeline\n",
    "    df = preprocessor.fit_transform(df)\n",
    "\n",
    "    # Perform PCA and select the best 6-15 features\n",
    "    pca = PCA(n_components=6)\n",
    "    df = pca.fit_transform(df)\n",
    "\n",
    "    # Split the data into train and test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df, df['went_on_backorder'], test_size=0.25, random_state=0)\n",
    "\n",
    "    # Build the logistic regression model\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model\n",
    "    accuracy = accuracy_score(y_test, model.predict(X_test))\n",
    "    roc_auc = roc_auc_score(y_test, model.predict_proba(X_test)[:, 1])\n",
    "    print('Accuracy:', accuracy)\n",
    "    print('ROC AUC:', roc_auc)\n",
    "\n",
    "    return model\n",
    "# model = backorder_model(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Step 1: Create the pipeline\n",
    "def get_transformer():\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('encoder', OrdinalEncoder(categories=[['No', 'Yes']]*len(obj_cols)))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_cols),\n",
    "            ('cat', categorical_transformer, obj_cols)\n",
    "        ])\n",
    "    return preprocessor\n",
    "\n",
    "# Step 2: Upsample or Downsample the target variable\n",
    "def balance_dataset(X, y):\n",
    "    X_majority = X[y == 'No']\n",
    "    X_minority = X[y == 'Yes']\n",
    "\n",
    "    y_majority = y[y == 'No']\n",
    "    y_minority = y[y == 'Yes']\n",
    "\n",
    "    X_minority_upsampled, y_minority_upsampled = resample(X_minority, y_minority,\n",
    "                                                           replace=True, n_samples=X_majority.shape[0])\n",
    "    X_upsampled = np.concatenate((X_majority, X_minority_upsampled))\n",
    "    y_upsampled = np.concatenate((y_majority, y_minority_upsampled))\n",
    "    return X_upsampled, y_upsampled\n",
    "\n",
    "# Step 3: Perform Upsampling or Downsampling on the target feature\n",
    "# X_upsampled, y_upsampled = balance_dataset(X, y)\n",
    "\n",
    "# # Step 4: Transform the data using the preprocessor pipeline\n",
    "# X = pd.DataFrame(X_upsampled, columns=df.columns[:-1])\n",
    "# X_transformed = get_transformer().fit_transform(X)\n",
    "\n",
    "# # Step 5: Perform PCA and select best 6-15 features\n",
    "# pca = PCA(n_components=15)\n",
    "# X_pca = pca.fit_transform(X_transformed)\n",
    "\n",
    "# # Step 6: Build the model with ML Algorithms\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_pca, y_upsampled, test_size=0.2, random_state=42)\n",
    "\n",
    "# model = SVC()\n",
    "# model.fit(X_train, y_train)\n",
    "\n",
    "# # Evaluate the model\n",
    "# y_pred = model.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import MinMaxScaler, OrdinalEncoder\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.utils import resample\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Step 1: Create the pipeline\n",
    "def get_transformer():\n",
    "    numeric_transformer = Pipeline(steps=[\n",
    "        ('imputer', SimpleImputer(strategy='median')),\n",
    "        ('scaler', MinMaxScaler())\n",
    "    ])\n",
    "\n",
    "    categorical_transformer = Pipeline(steps=[\n",
    "        ('encoder', OrdinalEncoder(categories=[['No', 'Yes']]*len(obj_cols)))\n",
    "    ])\n",
    "\n",
    "    preprocessor = ColumnTransformer(\n",
    "        transformers=[\n",
    "            ('num', numeric_transformer, num_cols),\n",
    "            ('cat', categorical_transformer, obj_cols)\n",
    "        ])\n",
    "    return preprocessor\n",
    "\n",
    "# Step 2: Upsample or Downsample the target variable\n",
    "def balance_dataset(X, y):\n",
    "    X_majority = X[y == 'No']\n",
    "    X_minority = X[y == 'Yes']\n",
    "\n",
    "    y_majority = y[y == 'No']\n",
    "    y_minority = y[y == 'Yes']\n",
    "\n",
    "    X_minority_upsampled, y_minority_upsampled = resample(X_minority, y_minority,\n",
    "                                                        replace=True, n_samples=X_majority.shape[0])\n",
    "    X_upsampled = np.concatenate((X_majority, X_minority_upsampled))\n",
    "    y_upsampled = np.concatenate((y_majority, y_minority_upsampled))\n",
    "    return X_upsampled, y_upsampled\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1676567, 21), (1676567,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[y == 'No'].shape, y[y == 'No'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Perform Upsampling or Downsampling on the target feature\n",
    "X_upsampled, y_upsampled = balance_dataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3353134, 3353134)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_upsampled), len(y_upsampled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "No     0.5\n",
       "Yes    0.5\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_upsampled).value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Transform the data using the preprocessor pipeline\n",
    "X = pd.DataFrame(X_upsampled, columns=df.columns[:-1])\n",
    "X_transformed = get_transformer().fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Perform PCA and select best 6-15 features\n",
    "pca = PCA(n_components=15)\n",
    "X_pca = pca.fit_transform(X_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Build the model with ML Algorithms\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca, y_upsampled, test_size=0.5, random_state=42)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_transformed, y_upsampled, test_size=0.5, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1676567, 15), (1676567,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "first = 100\n",
    "y_pred = model.predict(X_test[:first])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_test[:first], y_pred)\n",
    "acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" checked><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "model = RandomForestClassifier()\n",
    "model.fit(X_train[-200000:], y_train[-200000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "first = 100\n",
    "y_pred = model.predict(X_test[:first])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "acc = accuracy_score(y_test[:first], y_pred)\n",
    "acc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Score:\n",
    "\n",
    "- `RandomForest:` 90% - 95%\n",
    "- `LogisticRegression:` 50% - 65%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
